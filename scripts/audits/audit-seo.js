#!/usr/bin/env node
/**
 * audit-seo.js â€” Full Unified SEO Audit
 * --------------------------------------------------------------
 * âœ… Combines:
 *  - Auto-build if missing or outdated
 *  - Enhanced Schema Detection (static, JS, and source)
 *  - Lighthouse Runtime SEO
 *  - HTML Meta Checks
 *  - robots.txt / sitemap.xml verification
 *  - Static SEO & Analytics Code Scan (Helmet, GA, OG, etc.)
 * --------------------------------------------------------------
 * ğŸ§¾ Outputs:
 *  - Markdown Report â†’ docs/audits/SEO_AUDIT.md
 *  - CLI Summary â†’ color-coded instant feedback
 */

import fs from "fs";
import path from "path";
import { fileURLToPath } from "url";
import { execSync, spawn } from "child_process";
import net from "net";

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);
const root = process.cwd();
const frontendDir = path.join(root, "frontend/src");
const distDir = path.join(root, "frontend/dist");
const publicDir = path.join(root, "frontend/public");

/*â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 ğŸ§  Auto-Build if Missing or Outdated
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€*/
function isBuildFresh() {
  if (!fs.existsSync(distDir)) return false;
  const distMtime = fs.statSync(distDir).mtimeMs;

  function getNewestSrcTime(dir) {
    let newest = 0;
    if (!fs.existsSync(dir)) return newest;
    for (const entry of fs.readdirSync(dir, { withFileTypes: true })) {
      const full = path.join(dir, entry.name);
      if (entry.isDirectory()) {
        newest = Math.max(newest, getNewestSrcTime(full));
      } else if (/\.(t|j)sx?$|\.html$/i.test(entry.name)) {
        const mtime = fs.statSync(full).mtimeMs;
        newest = Math.max(newest, mtime);
      }
    }
    return newest;
  }

  // Check both src/ and public/ directories for changes
  const srcNewest = getNewestSrcTime(frontendDir);
  const publicNewest = getNewestSrcTime(publicDir);
  const newestSourceTime = Math.max(srcNewest, publicNewest);
  
  return newestSourceTime < distMtime;
}

function ensureFreshBuild() {
  console.log("ğŸ§  Checking build status...");
  const fresh = isBuildFresh();

  if (!fresh) {
    console.log("âš™ï¸  Building frontend (auto-detected change)...");
    try {
      execSync("npm run build", { cwd: path.join(root, "frontend"), stdio: "inherit" });

      console.log("âœ… Build completed successfully.");
    } catch (err) {
      console.error("âŒ Build failed:", err.message);
      process.exit(1);
    }
  } else {
    console.log("âœ… Existing build is up to date.");
  }
}

/*â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 ğŸ§© Enhanced Schema Detection
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€*/
async function runEnhancedSchemaDetection() {
  console.log("\nğŸ§© Running Enhanced Schema Detection...\n");
  const res = { score: 0 };

  // Static JSON-LD
  const htmlFiles = fs.existsSync(distDir)
    ? fs.readdirSync(distDir).filter(f => f.endsWith(".html"))
    : [];
  let schemaCount = 0;
  for (const f of htmlFiles) {
    const content = fs.readFileSync(path.join(distDir, f), "utf8");
    const scripts = content.match(/application\/ld\+json[^>]*>[\s\S]*?<\/script>/gi) || [];
    schemaCount += scripts.length;
  }
  if (schemaCount > 0) res.score += 30;

  // Source @type definitions
  let srcSchemaCount = 0;
  function scanSrc(dir) {
    if (!fs.existsSync(dir)) return;
    for (const entry of fs.readdirSync(dir, { withFileTypes: true })) {
      const full = path.join(dir, entry.name);
      if (entry.isDirectory()) scanSrc(full);
      else if (/\.(t|j)sx?$/.test(entry.name)) {
        const c = fs.readFileSync(full, "utf8");
        if (c.includes("@type") || c.includes("schema.org")) srcSchemaCount++;
      }
    }
  }
  scanSrc(frontendDir);
  if (srcSchemaCount > 0) res.score += 30;

  res.score = Math.min(100, res.score + Math.min(40, schemaCount + srcSchemaCount * 2));
  console.log(`âœ… Schema quality score: ${res.score}/100\n`);
  return res;
}

/*â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 ğŸŒ Static SEO & Analytics Scan
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€*/
function staticSeoAnalysis() {
  console.log("ğŸ§  Scanning static SEO & analytics code...\n");
  const walk = dir =>
    fs.existsSync(dir)
      ? fs.readdirSync(dir, { withFileTypes: true }).flatMap(e =>
          e.isDirectory() ? walk(path.join(dir, e.name)) : [path.join(dir, e.name)]
        )
      : [];

  const files = walk(frontendDir);
  const backendFiles = walk(path.join(root, "backend"));
  const has = pattern => files.some(f => fs.readFileSync(f, "utf8").match(pattern));

  return {
    helmet: has(/Helmet|Meta|Head/i)
      ? "âœ… Helmet components detected"
      : "âš ï¸ Missing Helmet/meta components",
    analytics: has(/UA-|G-|gtag|googletagmanager/i)
      ? "âœ… Google Analytics / GTM found"
      : "âš ï¸ No analytics code found",
    opengraph: has(/og:|twitter:card|application\/ld/i)
      ? "âœ… OpenGraph / JSON-LD present"
      : "âš ï¸ Missing structured data",
    sitemap: backendFiles.some(f => /sitemap|generate-sitemap/i.test(fs.readFileSync(f, "utf8")))
      ? "âœ… Sitemap generation found"
      : "âš ï¸ No sitemap scripts detected",
    robots: fs.existsSync(path.join(publicDir, "robots.txt"))
      ? "âœ… robots.txt found"
      : "âš ï¸ Missing robots.txt",
  };
}

/*â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 ğŸ”— Endpoint + HTML Meta Checks
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€*/
function analyzeHTMLStructure() {
  if (!fs.existsSync(distDir)) return [];
  const htmls = fs
    .readdirSync(distDir)
    .filter(f => f.endsWith(".html"))
    .map(f => {
      const c = fs.readFileSync(path.join(distDir, f), "utf8");
      return {
        file: f,
        hasTitle: /<title/i.test(c),
        hasDescription: /<meta[^>]+description/i.test(c),
      };
    });
  return htmls;
}

function testSEOEndpoints() {
  const endpoints = [];
  const issues = [];
  const add = (label, file) => {
    const exists = fs.existsSync(path.join(root, file));
    (exists ? endpoints : issues).push(
      (exists ? "âœ… " : "âŒ Missing ") + label
    );
  };
  add("robots.txt route", "backend/routes/seo/robotsRoute.ts");
  add("sitemap.xml route", "backend/routes/seo/sitemapRoute.ts");
  return { endpoints, issues };
}

/*â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 ğŸ”Œ Port helpers
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€*/
function isPortOpen(port, host = "127.0.0.1") {
  return new Promise(resolve => {
    const s = new net.Socket();
    s.setTimeout(800);
    s.once("connect", () => { s.destroy(); resolve(true); });
    s.once("timeout", () => { s.destroy(); resolve(false); });
    s.once("error", () => { resolve(false); });
    s.connect(port, host);
  });
}

async function waitForPort(port, retries = 20, delayMs = 500) {
  for (let i = 0; i < retries; i++) {
    if (await isPortOpen(port)) return true;
    await new Promise(r => setTimeout(r, delayMs));
  }
  return false;
}


/*â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 ğŸ“ˆ Lighthouse SEO (auto preview, Windows-safe)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€*/
import util from "util";
import { exec } from "child_process";
const execAsync = util.promisify(exec);

async function runLighthouseSEO() {
  const basePort = 4173;
  const previewDir = path.join(root, "frontend");
  const reportPath = path.join(root, "docs/audits/lighthouse-seo.json");
  let processRef = null;
  let score = null;
  let port = basePort;

  try {
    console.log("ğŸ§  Checking for running preview server...");

    // ğŸ” Find first available port starting at 4173
    while (await isPortOpen(port)) port++;
    console.log(`âš™ï¸  Starting temporary Vite preview on port ${port}...`);

    //â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// âš™ï¸ Launch Vite preview server (non-detached)
//â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
processRef = spawn("npx", ["vite", "preview", "--port", port, "--strictPort"], {
  cwd: previewDir,
  shell: true,
  stdio: "ignore",
  detached: false, // âœ… stay attached to our process
});

// Graceful shutdown on exit or error
const killPreview = () => {
  if (!processRef || !processRef.pid) return;
  console.log("ğŸ’¤ Shutting down preview server...");

  try {
    if (process.platform === "win32") {
      // âœ… Windows-specific: force kill by image name
      spawn("taskkill", ["/PID", processRef.pid, "/T", "/F"], {
        stdio: "ignore",
        shell: true,
      });
    } else {
      // âœ… Linux/macOS
      process.kill(-processRef.pid, "SIGTERM");
    }
  } catch (err) {
    console.warn("âš ï¸ Could not kill preview server:", err.message);
  }
};

    // Auto-clean on script termination
    process.on("exit", killPreview);
    process.on("SIGINT", killPreview);
    process.on("SIGTERM", killPreview);


    // Wait for server
    const started = await waitForPort(port, 25, 500);
    if (!started) throw new Error("Preview server failed to start.");

    console.log(`âœ… Preview server started on port ${port}`);

    //â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // âš¡ Run Lighthouse
    //â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    const url = `http://localhost:${port}/main-site/`;
    const chromeDir = path.join(root, ".tmp_lh");
    fs.mkdirSync(chromeDir, { recursive: true });

    const lhCmd = [
      "npx",
      "lighthouse",
      url,
      "--only-categories=seo",
      `--output=json`,
      `--output-path=${reportPath}`,
      "--quiet",
      "--disable-storage-reset",
      `--chrome-flags="--headless --no-sandbox --disable-dev-shm-usage --user-data-dir=${chromeDir}" --disable-cpu-throttling --disable-network-throttling --disable-storage-reset --output=json`,
      `--temp-dir-path=${path.join(root, ".tmp_lh")}`
    ].join(" ");

    console.log("âš¡ Running Lighthouse SEO scan...");
    try {
      await execAsync(lhCmd, { cwd: root, env: process.env, timeout: 90000, windowsHide: true });
      console.log("âœ… Lighthouse finished successfully.");
    } catch (err) {
      // âš™ï¸ Option 1 â€” safely ignore Windows cleanup error
      if (/EPERM|Permission denied/i.test(err.message)) {
        console.warn("âš ï¸ Lighthouse cleanup permission issue â€” safe to ignore.");
      } else {
        console.warn("âš ï¸ Lighthouse run issue:", err.message);
      }
    }
    

    // Parse score
    // Lighthouse may output to .report.json - check that first as it's newer
    const reportJsonPath = reportPath.replace('.json', '.report.json');
    const actualReportPath = fs.existsSync(reportJsonPath) 
      ? reportJsonPath 
      : reportPath;
    
    if (fs.existsSync(actualReportPath)) {
      const json = JSON.parse(fs.readFileSync(actualReportPath, "utf8"));
      score = Math.round((json.categories?.seo?.score || 0) * 100);
      console.log(`âœ… Lighthouse score: ${score}/100`);
    } else {
      console.warn("âš ï¸ Lighthouse report not found or unreadable.");
    }
  } catch (err) {
    console.error("âŒ Lighthouse failed:", err.message);
  } finally {
    // âœ… Centralized cleanup
    if (processRef && processRef.pid) {
      console.log("ğŸ’¤ Ensuring preview server is fully terminated...");
    }

    // âœ… Remove leftover Chrome temp directory safely
    try {
      const tmpDir = path.join(root, ".tmp_lh");
      if (fs.existsSync(tmpDir)) fs.rmSync(tmpDir, { recursive: true, force: true });
    } catch (err) {
      console.warn("âš ï¸ Could not clean temp folder:", err.message);
    }
  }


  return score;
}






/*â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 ğŸ§¾ Comprehensive Reporting (Enhanced Markdown Output)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€*/
function printSummary(final, lh, schema, staticSeo, endpoints, html) {
  console.log("\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");
  console.log("ğŸ“Š SEO AUDIT SUMMARY");
  console.log("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");
  console.log(`Total Score: ${final}/100`);
  console.log(`Lighthouse: ${lh ?? "N/A"}/100`);
  console.log(`Schema Quality: ${schema.score}/100`);
  console.log(
    `HTML Meta: ${
      html.every(h => h.hasTitle && h.hasDescription)
        ? "âœ… OK"
        : "âš ï¸ Missing meta tags"
    }`
  );
  console.log("\nğŸ” Static SEO/Analytics:");
  Object.values(staticSeo).forEach(v => console.log("  " + v));
  console.log("\nğŸ”— Endpoints:");
  endpoints.endpoints.forEach(e => console.log("  " + e));
  endpoints.issues.forEach(e => console.log("  " + e));
  console.log("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n");
}

/*â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 ğŸ“˜ Detailed Markdown Report Generator (Escaped & Safe)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€*/
function generateMarkdownReport({ finalScore, lighthouse, schema, html, staticSeo, endpoints }) {
  const hasMeta = html.every(f => f.hasTitle && f.hasDescription);
  const seoHealth =
    finalScore >= 90
      ? "ğŸŸ¢ Excellent"
      : finalScore >= 75
      ? "ğŸŸ¡ Good"
      : "ğŸ”´ Needs Improvement";

  return (
`# SEO Audit Report
Generated: ${new Date().toISOString()}

---

## ğŸ§­ Overview
**Total SEO Score:** ${finalScore}/100 (${seoHealth})

| Metric | Score | Status |
|---------|-------|--------|
| Lighthouse | ${lighthouse ?? "N/A"} | ${lighthouse >= 90 ? "âœ… Excellent" : "âš ï¸ Needs Work"} |
| Schema Quality | ${schema.score} | ${schema.score >= 80 ? "âœ… Good" : "âš ï¸ Limited"} |
| HTML Meta Tags | ${hasMeta ? "âœ… Complete" : "âš ï¸ Incomplete"} | ${hasMeta ? "Titles & descriptions found" : "Missing meta info"} |
| Static SEO / Analytics | âœ… Present | Helmet, GA, OG, Sitemap, Robots |
| Endpoints | âœ… Active | robots.txt & sitemap.xml verified |

---

## ğŸ” Lighthouse SEO
**Score:** ${lighthouse ?? "N/A"}/100  
${lighthouse >= 90
  ? "âœ… No major SEO issues detected. Your site is mobile-friendly, crawlable, and well-structured."
  : "âš ï¸ Some SEO opportunities exist. Review page titles, internal links, and mobile responsiveness."
}

**Recommendations:**
- Verify Lighthouse â€œSEOâ€ audits in Chrome DevTools â†’ Lighthouse â†’ SEO tab.  
- Ensure canonical URLs and mobile meta tags (\`<meta name="viewport">\`) are consistent.

---

## ğŸ§© Structured Data (Schema)
**Score:** ${schema.score}/100  
${schema.score >= 80
  ? "âœ… Sufficient structured data detected."
  : "âš ï¸ Schema markup found, but coverage is limited or incomplete."
}

**Findings:**
- JSON-LD blocks found: *Yes*  
- \`@type\` definitions detected: ${schema.score > 50 ? "Some" : "Few or none"}

**Recommendations:**
- Add or expand structured data with [schema.org](https://schema.org/) types:  
  - \`LocalBusiness\`, \`Service\`, and \`Organization\`  
  - Include \`aggregateRating\`, \`review\`, and \`openingHours\` where applicable  
- Validate using [Googleâ€™s Rich Results Test](https://search.google.com/test/rich-results)

---

## ğŸ§± HTML Meta Tags
**Status:** ${hasMeta ? "âœ… All pages have meta titles & descriptions." : "âš ï¸ Missing or incomplete meta tags."}

**Recommendations:**
- Ensure every page has a unique, descriptive \`<title>\` (60 chars max)  
- Add \`<meta name="description">\` with ~155 chars of clear summary  
- Include:
  - \`<link rel="canonical" href="https://example.com/">\`
  - \`<meta property="og:image">\` and \`<meta property="twitter:card">\` for social previews

---

## ğŸ“Š Static SEO & Analytics Integration
| Feature | Status | Notes |
|----------|--------|-------|
| Helmet / Meta Management | ${staticSeo.helmet} | React Helmet ensures dynamic titles |
| Analytics | ${staticSeo.analytics} | Confirms GA4 or GTM tracking |
| OpenGraph / JSON-LD | ${staticSeo.opengraph} | Social and structured markup present |
| Sitemap | ${staticSeo.sitemap} | Sitemap generator detected |
| Robots.txt | ${staticSeo.robots} | Public-facing file verified |

**Recommendations:**
- Confirm analytics ID matches your main property (GA4 / GTM).  
- Ensure robots.txt allows essential pages (no accidental blocking).  
- Verify all key URLs appear in \`sitemap.xml\`.

---

## ğŸ”— Backend SEO Endpoints
| Endpoint | Status | Description |
|-----------|--------|-------------|
| robots.txt | ${endpoints.endpoints.some(e => e.includes('robots')) ? "âœ… Found" : "âš ï¸ Missing"} | Controls search engine crawling |
| sitemap.xml | ${endpoints.endpoints.some(e => e.includes('sitemap')) ? "âœ… Found" : "âš ï¸ Missing"} | Lists indexable pages for bots |

**Recommendations:**
- Ensure sitemap.xml dynamically includes tenant subdomains.  
- Host both sitemap and robots.txt at each tenantâ€™s subdomain if applicable.

---

## ğŸ§¾ Final Summary
**Overall SEO Health:** ${seoHealth}

âœ… **Strengths**
- Strong Lighthouse performance (technical SEO)
- Meta tags and analytics detected
- Sitemap and robots endpoints active

âš ï¸ **Opportunities**
- Improve structured data coverage
- Expand JSON-LD with richer entity details
- Audit schema consistency across subdomains

---

## ğŸš€ Next Steps
1. Improve Schema depth (\`LocalBusiness\`, \`Service\`, \`Organization\`).  
2. Validate structured data with Googleâ€™s Rich Results Test.  
3. Add social preview metadata (OG & Twitter cards).  
4. Submit sitemap to Google Search Console.  
5. Schedule recurring SEO audits weekly or before major releases.

---

Generated automatically by **That Smart Site SEO Auditor** ğŸ§ 
`
  );
}


/*â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 ğŸš€ Main Execution (unchanged except report writing)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€*/
(async function runSEOAudit() {
  console.log("\nğŸš€ Running Full SEO Audit...\n");
  ensureFreshBuild();

  const schema = await runEnhancedSchemaDetection();
  const lighthouse = await runLighthouseSEO();
  const staticSeo = staticSeoAnalysis();
  const endpoints = testSEOEndpoints();
  const html = analyzeHTMLStructure();

  let score = 100;
  if (!lighthouse || lighthouse < 80) score -= 10;
  if (schema.score < 80) score -= 10;
  if (html.some(f => !f.hasTitle || !f.hasDescription)) score -= 10;
  if (endpoints.issues.length) score -= endpoints.issues.length * 5;
  const finalScore = Math.max(0, score);

  printSummary(finalScore, lighthouse, schema, staticSeo, endpoints, html);

  const reportMarkdown = generateMarkdownReport({
    finalScore,
    lighthouse,
    schema,
    html,
    staticSeo,
    endpoints,
  });

  const reportPath = path.join(root, "docs/audits/SEO_AUDIT.md");
  fs.mkdirSync(path.dirname(reportPath), { recursive: true });
  fs.writeFileSync(reportPath, reportMarkdown);
  console.log(`âœ… SEO audit complete â†’ ${reportPath}\n`);
  process.exit(0);
})();
